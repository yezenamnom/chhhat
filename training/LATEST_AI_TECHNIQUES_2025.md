# ğŸ”¥ Ø£Ø­Ø¯Ø« ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ 2024-2025 - Latest AI Techniques
# ğŸš€ Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«: Ø¯ÙŠØ³Ù…Ø¨Ø± 2024 - Ø£Ø­Ø¯Ø« Ø§Ù„ØªØ·ÙˆØ±Ø§Øª ÙˆØ§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨

---

## ğŸ“‹ Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª

1. [ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù€ Prompting Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©](#advanced-prompting)
2. [RAG (Retrieval-Augmented Generation)](#rag)
3. [Fine-Tuning Strategies](#fine-tuning)
4. [Multi-Agent Systems](#multi-agent)
5. [Reasoning Techniques](#reasoning)
6. [Ø£Ø¯ÙˆØ§Øª ÙˆØªÙ‚Ù†ÙŠØ§Øª Ø­Ø¯ÙŠØ«Ø©](#modern-tools)

---

## ğŸ¯ 1. ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù€ Prompting Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© {#advanced-prompting}

### 1.1 Chain-of-Thought (CoT) Prompting

```
Ø§Ù„Ù…Ù†Ù‡Ø¬ÙŠØ©:
1. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø¥Ù„Ù‰ Ø®Ø·ÙˆØ§Øª
2. Ø§Ù„ØªÙÙƒÙŠØ± ÙÙŠ ÙƒÙ„ Ø®Ø·ÙˆØ©
3. Ø±Ø¨Ø· Ø§Ù„Ø®Ø·ÙˆØ§Øª
4. Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬

Ù…Ø«Ø§Ù„:
Ø§Ù„Ø³Ø¤Ø§Ù„: "Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙ†Ø§ 5 ØªÙØ§Ø­Ø§Øª ÙˆØ£ÙƒÙ„Ù†Ø§ 2ØŒ Ø«Ù… Ø§Ø´ØªØ±ÙŠÙ†Ø§ 3ØŒ ÙƒÙ… Ù„Ø¯ÙŠÙ†Ø§ Ø§Ù„Ø¢Ù†ØŸ"

Ø§Ù„ØªÙÙƒÙŠØ±:
Ø®Ø·ÙˆØ© 1: Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© - Ù„Ø¯ÙŠÙ†Ø§ 5 ØªÙØ§Ø­Ø§Øª
Ø®Ø·ÙˆØ© 2: Ø¨Ø¹Ø¯ Ø§Ù„Ø£ÙƒÙ„ - 5 - 2 = 3 ØªÙØ§Ø­Ø§Øª
Ø®Ø·ÙˆØ© 3: Ø¨Ø¹Ø¯ Ø§Ù„Ø´Ø±Ø§Ø¡ - 3 + 3 = 6 ØªÙØ§Ø­Ø§Øª
Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬: Ù„Ø¯ÙŠÙ†Ø§ 6 ØªÙØ§Ø­Ø§Øª Ø§Ù„Ø¢Ù†
```

### 1.2 Tree of Thoughts (ToT)

```
Ø§Ø³ØªÙƒØ´Ø§Ù Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª:

Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:
  â†“
ØªÙˆÙ„ÙŠØ¯ ÙØ±Ø¶ÙŠØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©:
  - Ø§Ù„ÙØ±Ø¶ÙŠØ© A
  - Ø§Ù„ÙØ±Ø¶ÙŠØ© B
  - Ø§Ù„ÙØ±Ø¶ÙŠØ© C
  â†“
ØªÙ‚ÙŠÙŠÙ… ÙƒÙ„ ÙØ±Ø¶ÙŠØ©:
  - Ø§Ù„ÙØ±Ø¶ÙŠØ© A: Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© 70%
  - Ø§Ù„ÙØ±Ø¶ÙŠØ© B: Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© 85%
  - Ø§Ù„ÙØ±Ø¶ÙŠØ© C: Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© 60%
  â†“
Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£ÙØ¶Ù„:
  â†’ Ø§Ù„ÙØ±Ø¶ÙŠØ© B (85%)
  â†“
Ø§Ù„ØªØ¹Ù…Ù‚ ÙÙŠ Ø§Ù„ÙØ±Ø¶ÙŠØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
```

### 1.3 Self-Consistency

```
ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©:
  - Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© 1
  - Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© 2
  - Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© 3
  - Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© 4
  - Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© 5
  â†“
ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ³Ø§Ù‚:
  - Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© 1: ØªØ¸Ù‡Ø± 3 Ù…Ø±Ø§Øª
  - Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© 2: ØªØ¸Ù‡Ø± 2 Ù…Ø±Ø§Øª
  - Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© 3: ØªØ¸Ù‡Ø± 0 Ù…Ø±Ø§Øª
  â†“
Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ø§ØªØ³Ø§Ù‚Ø§Ù‹:
  â†’ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© 1 (Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹)
```

### 1.4 Chain-of-Verification (CoVe)

```
1. Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø·Ø© Ø§Ù„ØªØ­Ù‚Ù‚:
   - Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªØ§Ø¬ Ù„Ù„ØªØ­Ù‚Ù‚ØŸ
   - ÙƒÙŠÙ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡ØŸ
   - Ù…Ø§ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©ØŸ

2. ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù‚Ù‚:
   - Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø®Ø·ÙˆØ© 1
   - Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø®Ø·ÙˆØ© 2
   - Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø®Ø·ÙˆØ© 3

3. Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬:
   - Ù‡Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù†Ø¬Ø­ØŸ
   - Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£Ø®Ø·Ø§Ø¡ØŸ
   - Ù‡Ù„ ÙŠØ­ØªØ§Ø¬ ØªØµØ­ÙŠØ­ØŸ

4. ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡:
   - ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
   - ØªØµØ­ÙŠØ­Ù‡Ø§
   - Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù‚Ù‚

5. Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:
   - Ù…Ø±Ø§Ø¬Ø¹Ø© Ø´Ø§Ù…Ù„Ø©
   - Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø¯Ù‚Ø©
```

### 1.5 ReAct (Reasoning + Acting)

```
Loop:
  Thought: [Ø§Ù„ØªÙÙƒÙŠØ± ÙÙŠ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©]
    â†’ Ù…Ø§ Ø§Ù„Ø°ÙŠ Ø£Ø­ØªØ§Ø¬ ÙØ¹Ù„Ù‡ØŸ
    â†’ Ù…Ø§ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©ØŸ
    â†’ Ù…Ø§ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ØŸ
  
  Action: [ØªÙ†ÙÙŠØ° Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡]
    â†’ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
    â†’ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯Ø§Ø©
    â†’ ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ©
  
  Observation: [Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©]
    â†’ Ù…Ø§ Ø§Ù„Ù†ØªÙŠØ¬Ø©ØŸ
    â†’ Ù‡Ù„ Ù†Ø¬Ø­ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ØŸ
    â†’ Ù…Ø§ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©ØŸ
  
  Until: [Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø£Ùˆ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù‡Ø¯Ù]
```

### 1.6 Reflection & Refinement

```
1. Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¬Ø§Ø¨Ø© Ø£ÙˆÙ„ÙŠØ©:
   â†’ Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
   â†’ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©

2. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
   â†’ Ù…Ø±Ø§Ø¬Ø¹Ø© ÙƒÙ„ Ø¬Ø²Ø¡
   â†’ ØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©
   â†’ ØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù

3. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„:
   â†’ Ù…Ø§ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ØŸ
   â†’ Ù…Ø§ Ø§Ù„Ù†ÙˆØ§Ù‚ØµØŸ
   â†’ Ù…Ø§ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©ØŸ

4. ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
   â†’ ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
   â†’ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø§Ù‚ØµØ©
   â†’ ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØ¶ÙˆØ­

5. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØµÙŠØ§ØºØ©:
   â†’ Ø¨Ù†Ø§Ø¡ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø­Ø³Ù‘Ù†Ø©
   â†’ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø§ØªØ³Ø§Ù‚
   â†’ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¯Ù‚Ø©
```

---

## ğŸ” 2. RAG (Retrieval-Augmented Generation) {#rag}

### 2.1 RAG Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Query    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query Embeddingâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vector Search   â”‚
â”‚  (Similarity)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Context Retrievalâ”‚
â”‚  (Top K docs)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Generation  â”‚
â”‚  (Query + Context)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Final Answer   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 RAG Components

```python
# 1. Document Processing
class DocumentProcessor:
    def process(self, documents: List[str]) -> List[Document]:
        # Chunking
        chunks = self.chunk_documents(documents)
        # Cleaning
        cleaned = self.clean_chunks(chunks)
        # Metadata extraction
        metadata = self.extract_metadata(cleaned)
        return cleaned

# 2. Embedding Generation
class EmbeddingService:
    def __init__(self, model: str = 'text-embedding-ada-002'):
        self.model = model
    
    def generate_embeddings(self, texts: List[str]) -> List[Vector]:
        # Generate embeddings using OpenAI/Cohere/etc.
        return embeddings

# 3. Vector Store
class VectorStore:
    def __init__(self, store_type: str = 'pinecone'):
        self.store = self.initialize_store(store_type)
    
    def add_documents(self, documents: List[Document], embeddings: List[Vector]):
        # Store documents with embeddings
        pass
    
    def search(self, query_embedding: Vector, top_k: int = 5) -> List[Document]:
        # Similarity search
        return similar_documents

# 4. RAG Pipeline
class RAGPipeline:
    def __init__(self):
        self.processor = DocumentProcessor()
        self.embedding_service = EmbeddingService()
        self.vector_store = VectorStore()
        self.llm = LLMService()
    
    async def query(self, user_query: str) -> str:
        # 1. Generate query embedding
        query_embedding = self.embedding_service.generate_embeddings([user_query])[0]
        
        # 2. Retrieve relevant documents
        relevant_docs = self.vector_store.search(query_embedding, top_k=5)
        
        # 3. Build context
        context = self.build_context(relevant_docs)
        
        # 4. Generate answer
        prompt = self.build_prompt(user_query, context)
        answer = await self.llm.generate(prompt)
        
        return answer
```

### 2.3 Advanced RAG Techniques

#### Multi-Query RAG
```python
class MultiQueryRAG:
    def generate_queries(self, original_query: str) -> List[str]:
        prompt = f"""
        Given the following question, generate 3 different ways to ask the same question.
        Original question: {original_query}
        
        Generate 3 variations:
        """
        queries = self.llm.generate(prompt)
        return [original_query] + queries
    
    async def query(self, user_query: str) -> str:
        queries = self.generate_queries(user_query)
        all_docs = []
        
        for query in queries:
            docs = self.vector_store.search(query)
            all_docs.extend(docs)
        
        # Deduplicate and rank
        unique_docs = self.deduplicate_and_rank(all_docs)
        
        # Generate answer with best context
        return await self.generate_answer(user_query, unique_docs)
```

#### Reranking
```python
class RerankedRAG:
    def __init__(self):
        self.ranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    
    def rerank(self, query: str, documents: List[Document], top_k: int = 5) -> List[Document]:
        # Score each document
        scores = []
        for doc in documents:
            score = self.ranker.predict([query, doc.text])
            scores.append((score, doc))
        
        # Sort by score
        scores.sort(reverse=True, key=lambda x: x[0])
        
        # Return top K
        return [doc for _, doc in scores[:top_k]]
```

---

## ğŸ“ 3. Fine-Tuning Strategies {#fine-tuning}

### 3.1 Full Fine-Tuning

```
Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:
- ØªØ­ÙƒÙ… ÙƒØ§Ù…Ù„ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
- Ø£ÙØ¶Ù„ Ø£Ø¯Ø§Ø¡ Ù…Ø­ØªÙ…Ù„
- Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ØªØ®ØµØµØ© Ø¬Ø¯Ø§Ù‹

Ø§Ù„Ø¹ÙŠÙˆØ¨:
- ÙŠØªØ·Ù„Ø¨ Ù…ÙˆØ§Ø±Ø¯ ÙƒØ¨ÙŠØ±Ø© (GPU memory)
- Ø¨Ø·ÙŠØ¡ Ù†Ø³Ø¨ÙŠØ§Ù‹
- Ø®Ø·Ø± Ø§Ù„Ù€ overfitting

Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
- Ù…Ù‡Ø§Ù… Ù…ØªØ®ØµØµØ© Ø¬Ø¯Ø§Ù‹
- Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ ÙƒØ¨ÙŠØ±Ø©
- Ù…ÙˆØ§Ø±Ø¯ ÙƒØ§ÙÙŠØ© Ù…ØªØ§Ø­Ø©
```

### 3.2 LoRA (Low-Rank Adaptation)

```python
# LoRA Configuration
lora_config = {
    "r": 16,              # Rank
    "lora_alpha": 32,     # Scaling factor
    "target_modules": ["q_proj", "v_proj"],  # Modules to adapt
    "lora_dropout": 0.1,
    "bias": "none",
    "task_type": "CAUSAL_LM"
}

# LoRA Advantages:
# - Only trains small number of parameters
# - Much faster than full fine-tuning
# - Less memory required
# - Can combine multiple LoRA adapters
```

### 3.3 QLoRA (Quantized LoRA)

```python
# QLoRA Configuration
qlora_config = {
    "load_in_4bit": True,      # 4-bit quantization
    "bnb_4bit_compute_dtype": "float16",
    "bnb_4bit_use_double_quant": True,
    "bnb_4bit_quant_type": "nf4",
    "lora_config": lora_config
}

# QLoRA Advantages:
# - Even less memory (4-bit instead of 16-bit)
# - Can run on consumer GPUs
# - Still maintains good performance
# - Fast training
```

### 3.4 Prompt Tuning

```
Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:
- ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù€ prompts ÙÙ‚Ø·
- Ø¥Ø¶Ø§ÙØ© examples ÙÙŠ context
- Ø§Ø³ØªØ®Ø¯Ø§Ù… few-shot learning
- ØªØ­Ø³ÙŠÙ† prompt engineering

Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:
- Ù„Ø§ ÙŠØªØ·Ù„Ø¨ ØªØ¯Ø±ÙŠØ¨
- Ø³Ø±ÙŠØ¹ Ø¬Ø¯Ø§Ù‹
- Ø³Ù‡Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
- Ù„Ø§ ÙŠØ­ØªØ§Ø¬ Ù…ÙˆØ§Ø±Ø¯ Ø¥Ø¶Ø§ÙÙŠØ©

Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
- Ù…Ù‡Ø§Ù… Ø¨Ø³ÙŠØ·Ø© Ø¥Ù„Ù‰ Ù…ØªÙˆØ³Ø·Ø©
- Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø¯ÙˆØ¯Ø©
- Ø³Ø±Ø¹Ø© ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
```

### 3.5 Fine-Tuning Best Practices

```python
# 1. Data Preparation
def prepare_training_data(raw_data: List[Dict]) -> List[Dict]:
    training_data = []
    for item in raw_data:
        training_data.append({
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": item["question"]},
                {"role": "assistant", "content": item["answer"]}
            ]
        })
    return training_data

# 2. Hyperparameter Tuning
hyperparameters = {
    "learning_rate": 2e-5,      # Start with 2e-5
    "batch_size": 4,            # Adjust based on GPU memory
    "num_epochs": 3,            # Usually 3-5 epochs
    "warmup_steps": 500,        # 10% of training steps
    "weight_decay": 0.01,       # Regularization
    "max_seq_length": 2048      # Based on model and data
}

# 3. Evaluation
def evaluate_model(model, test_data):
    metrics = {
        "accuracy": calculate_accuracy(model, test_data),
        "bleu_score": calculate_bleu(model, test_data),
        "rouge_score": calculate_rouge(model, test_data),
        "perplexity": calculate_perplexity(model, test_data)
    }
    return metrics
```

---

## ğŸ¤– 4. Multi-Agent Systems {#multi-agent}

### 4.1 Agent Architecture

```python
class Agent:
    def __init__(self, name: str, role: str, capabilities: List[str]):
        self.name = name
        self.role = role
        self.capabilities = capabilities
        self.memory = AgentMemory()
        self.tools = self.load_tools()
    
    async def execute(self, task: Task) -> Result:
        # 1. Understand task
        understanding = await self.understand_task(task)
        
        # 2. Plan approach
        plan = await self.create_plan(understanding)
        
        # 3. Execute plan
        result = await self.execute_plan(plan)
        
        # 4. Reflect and improve
        reflection = await self.reflect(result)
        
        return result
    
    async def communicate(self, message: Message, recipient: Agent):
        # Inter-agent communication
        await recipient.receive(message)

class MultiAgentSystem:
    def __init__(self, agents: List[Agent]):
        self.agents = agents
        self.coordinator = Coordinator(agents)
    
    async def solve(self, problem: Problem) -> Solution:
        # Distribute tasks
        tasks = self.coordinator.decompose(problem)
        
        # Assign to agents
        assignments = self.coordinator.assign(tasks, self.agents)
        
        # Execute in parallel/sequence
        results = await self.coordinator.execute(assignments)
        
        # Synthesize solution
        solution = self.coordinator.synthesize(results)
        
        return solution
```

### 4.2 Agent Specialization

```python
# Research Agent
class ResearchAgent(Agent):
    def __init__(self):
        super().__init__(
            name="Researcher",
            role="Research and information gathering",
            capabilities=["web_search", "document_analysis", "fact_checking"]
        )
    
    async def research(self, topic: str) -> ResearchReport:
        # Search multiple sources
        sources = await self.search_sources(topic)
        
        # Analyze and synthesize
        report = await self.analyze(sources)
        
        return report

# Coding Agent
class CodingAgent(Agent):
    def __init__(self):
        super().__init__(
            name="Developer",
            role="Code generation and debugging",
            capabilities=["code_generation", "code_review", "testing"]
        )
    
    async def develop(self, requirements: str) -> CodeSolution:
        # Generate code
        code = await self.generate_code(requirements)
        
        # Test and debug
        tested_code = await self.test_and_fix(code)
        
        return CodeSolution(code=tested_code)

# Analysis Agent
class AnalysisAgent(Agent):
    def __init__(self):
        super().__init__(
            name="Analyst",
            role="Data analysis and insights",
            capabilities=["data_analysis", "statistics", "visualization"]
        )
    
    async def analyze(self, data: Data) -> AnalysisReport:
        # Perform analysis
        insights = await self.perform_analysis(data)
        
        # Generate report
        report = await self.generate_report(insights)
        
        return report
```

### 4.3 Agent Collaboration

```python
class CollaborativeSystem:
    def __init__(self):
        self.researcher = ResearchAgent()
        self.developer = CodingAgent()
        self.analyst = AnalysisAgent()
        self.coordinator = Coordinator()
    
    async def solve_complex_problem(self, problem: ComplexProblem) -> Solution:
        # 1. Research phase
        research_task = Task(
            agent=self.researcher,
            action="research",
            input=problem.description
        )
        research_result = await research_task.execute()
        
        # 2. Development phase (based on research)
        dev_task = Task(
            agent=self.developer,
            action="develop",
            input={
                "requirements": problem.requirements,
                "research": research_result
            }
        )
        dev_result = await dev_task.execute()
        
        # 3. Analysis phase (based on development)
        analysis_task = Task(
            agent=self.analyst,
            action="analyze",
            input={
                "code": dev_result.code,
                "research": research_result
            }
        )
        analysis_result = await analysis_task.execute()
        
        # 4. Synthesis
        solution = self.coordinator.synthesize([
            research_result,
            dev_result,
            analysis_result
        ])
        
        return solution
```

---

## ğŸ§  5. Reasoning Techniques {#reasoning}

### 5.1 Structured Reasoning

```python
class ReasoningEngine:
    def reason(self, problem: Problem) -> Solution:
        # 1. Decompose
        sub_problems = self.decompose(problem)
        
        # 2. Solve each
        solutions = []
        for sub_problem in sub_problems:
            solution = self.solve_sub_problem(sub_problem)
            solutions.append(solution)
        
        # 3. Synthesize
        final_solution = self.synthesize(solutions)
        
        # 4. Verify
        if self.verify(final_solution, problem):
            return final_solution
        else:
            return self.refine(final_solution)
```

### 5.2 Causal Reasoning

```
ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¨Ø¨ ÙˆØ§Ù„Ù†ØªÙŠØ¬Ø©:

Ø§Ù„Ø¸Ø§Ù‡Ø±Ø©:
  â†“
ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©:
  - Ø§Ù„Ø³Ø¨Ø¨ A (Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© 60%)
  - Ø§Ù„Ø³Ø¨Ø¨ B (Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© 30%)
  - Ø§Ù„Ø³Ø¨Ø¨ C (Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© 10%)
  â†“
ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ù„Ø©:
  - Ø¯Ù„ÙŠÙ„ ÙŠØ¯Ø¹Ù… A
  - Ø¯Ù„ÙŠÙ„ ÙŠØ¯Ø¹Ù… B
  - Ù„Ø§ Ø£Ø¯Ù„Ø© Ù„Ù€ C
  â†“
ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹:
  â†’ Ø§Ù„Ø³Ø¨Ø¨ A
  â†“
Ø§Ù„ØªØ­Ù‚Ù‚:
  - Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙØ±Ø¶ÙŠØ©
  - Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
  - ØªØ£ÙƒÙŠØ¯ Ø£Ùˆ Ù†ÙÙŠ
```

### 5.3 Analogical Reasoning

```
Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:
  â†“
Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø´Ø§ÙƒÙ„ Ù…Ø´Ø§Ø¨Ù‡Ø©:
  - Ø§Ù„Ù…Ø´ÙƒÙ„Ø© A (ØªØ´Ø§Ø¨Ù‡ 80%)
  - Ø§Ù„Ù…Ø´ÙƒÙ„Ø© B (ØªØ´Ø§Ø¨Ù‡ 60%)
  - Ø§Ù„Ù…Ø´ÙƒÙ„Ø© C (ØªØ´Ø§Ø¨Ù‡ 40%)
  â†“
ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:
  - Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© A
  - Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© B
  â†“
Ø§Ù„ØªÙƒÙŠÙ Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠ:
  - ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø­Ù„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
  - ØªØ·Ø¨ÙŠÙ‚Ù‡ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
```

---

## ğŸ› ï¸ 6. Ø£Ø¯ÙˆØ§Øª ÙˆØªÙ‚Ù†ÙŠØ§Øª Ø­Ø¯ÙŠØ«Ø© {#modern-tools}

### 6.1 LLM Frameworks

```python
# LangChain
from langchain import LLMChain, PromptTemplate
from langchain.llms import OpenAI

template = """Question: {question}
Answer: Let's think step by step."""

prompt = PromptTemplate(template=template, input_variables=["question"])
llm_chain = LLMChain(prompt=prompt, llm=OpenAI())

# LlamaIndex
from llama_index import VectorStoreIndex, SimpleDirectoryReader

documents = SimpleDirectoryReader('data').load_data()
index = VectorStoreIndex.from_documents(documents)
query_engine = index.as_query_engine()

# Haystack
from haystack import Pipeline
from haystack.nodes import EmbeddingRetriever, PromptNode

pipeline = Pipeline()
pipeline.add_node(component=retriever, name="Retriever", inputs=["Query"])
pipeline.add_node(component=prompt_node, name="PromptNode", inputs=["Retriever"])
```

### 6.2 Vector Databases

```python
# Pinecone
import pinecone

pinecone.init(api_key="your-api-key")
index = pinecone.Index("your-index")
index.upsert(vectors=[("id", embedding)])

# Weaviate
import weaviate

client = weaviate.Client("http://localhost:8080")
client.data_object.create(data_object, "Document")

# Qdrant
from qdrant_client import QdrantClient

client = QdrantClient("localhost", port=6333)
client.upsert(collection_name="documents", points=points)
```

### 6.3 Evaluation Tools

```python
# RAGAS (RAG Evaluation)
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy

dataset = {
    "question": ["What is the capital of France?"],
    "answer": ["Paris"],
    "contexts": [["France is a country..."]],
    "ground_truth": ["Paris"]
}

result = evaluate(
    dataset=dataset,
    metrics=[faithfulness, answer_relevancy]
)

# LangSmith
from langsmith import Client

client = Client()
run = client.create_run(
    name="my-test",
    inputs={"question": "What is AI?"},
    outputs={"answer": "Artificial Intelligence..."}
)
```

---

## ğŸ¯ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª 2025

### âœ… Ø§ÙØ¹Ù„:
- Ø§Ø³ØªØ®Ø¯Ù… Chain-of-Thought Ù„Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ø¹Ù‚Ø¯
- Ø·Ø¨Ù‚ RAG Ù„Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø«Ø©
- Ø§Ø³ØªØ®Ø¯Ù… LoRA/QLoRA Ù„Ù„Ù€ fine-tuning
- Ø·Ø¨Ù‚ Multi-Agent Ù„Ù„Ù€ tasks Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
- Ù‚ÙŠÙ‘Ù… Ø¨Ø§Ø³ØªÙ…Ø±Ø§Ø± ÙˆØ­Ø³Ù‘Ù†

### âŒ Ù„Ø§ ØªÙØ¹Ù„:
- Ù„Ø§ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù€ LLM ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† context
- Ù„Ø§ ØªÙ‡Ù…Ù„ Ø§Ù„Ù€ evaluation
- Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… full fine-tuning Ø¨Ø¯ÙˆÙ† Ø­Ø§Ø¬Ø©
- Ù„Ø§ ØªØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù€ safety ÙˆØ§Ù„Ù€ bias
- Ù„Ø§ ØªÙ†Ø³Ù Ø§Ù„Ù€ cost optimization

---

## ğŸ“š Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª

### Ø£Ø­Ø¯Ø« Ø§Ù„Ø£Ø¨Ø­Ø§Ø« (2024-2025):
- **Chain-of-Thought Prompting** (Wei et al., 2022)
- **Tree of Thoughts** (Yao et al., 2023)
- **ReAct** (Yao et al., 2023)
- **Chain-of-Verification** (Dhuliawala et al., 2023)
- **RAG** (Lewis et al., 2020)
- **LoRA** (Hu et al., 2021)
- **QLoRA** (Dettmers et al., 2023)
- **Multi-Agent Systems** (Park et al., 2023)

### Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§:
- LangChain / LangGraph
- LlamaIndex
- Haystack
- Pinecone / Weaviate / Qdrant
- RAGAS
- LangSmith

---

**Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«**: Ø¯ÙŠØ³Ù…Ø¨Ø± 2024  
**Ø§Ù„Ø¥ØµØ¯Ø§Ø±**: 3.0  
**Ø§Ù„Ø­Ø§Ù„Ø©**: ğŸ”¥ Ø£Ø­Ø¯Ø« Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª ÙˆØ§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ 2024-2025 ğŸ”¥


